{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage.segmentation import mark_boundaries\n",
    "#from skimage.util.montage import montage2d as montage\n",
    "import cv2\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.morphology import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img)\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n",
    "\n",
    "def mask_overlay(image, mask, color=(0, 1, 0)):\n",
    "    \"\"\"\n",
    "    Helper function to visualize mask on the top of the image\n",
    "    \"\"\"\n",
    "    mask = np.dstack((mask, mask, mask)) * np.array(color)\n",
    "    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)\n",
    "    img = image.copy()\n",
    "    ind = mask[:, :, 1] > 0\n",
    "    img[ind] = weighted_sum[ind]    \n",
    "    return img\n",
    "\n",
    "def imshow(img, mask, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    mask = mask.numpy().transpose((1, 2, 0))\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    plt.imshow(mask_overlay(img, mask))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/datasets/ee285f-public/airbus_ship_detection/'\n",
    "train_img_dir = os.path.join(input_dir, 'train_v2')\n",
    "test_img_dir = os.path.join(input_dir, 'test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231723 masks total\n",
      "192556 unique images\n"
     ]
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join(input_dir,\n",
    "                                 'train_ship_segmentations_v2.csv'))\n",
    "print(masks.shape[0], 'masks total')\n",
    "print(masks['ImageId'].value_counts().shape[0], 'unique images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, input_df, transform=None, mode='train_v2'):\n",
    "        group = list(input_df.groupby('ImageId'))\n",
    "        self.image_ids =  [_id for _id, _ in group] \n",
    "        self.image_masks = [m['EncodedPixels'].values for _,m in group]\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.img_transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "               \n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.image_ids[idx]\n",
    "        if self.mode == 'train_v2':\n",
    "            rgb_path = os.path.join(train_image_dir, img_file_name)\n",
    "        else:\n",
    "            rgb_path = os.path.join(test_image_dir, img_file_name)\n",
    "        img = imread(rgb_path)\n",
    "        mask = masks_as_image(self.image_masks[idx])\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            img, mask = self.transform(img, mask)\n",
    "\n",
    "        if self.mode == 'train_v2':\n",
    "            #return self.to_float_tensor(img), self.to_float_tensor(mask)\n",
    "            #eturn img, mask\n",
    "            return self.img_transform(img), torch.from_numpy(np.moveaxis(mask, -1, 0)).float()\n",
    "        else:\n",
    "            return self.img_transform(img), str(img_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference  https://github.com/ternaus/robot-surgery-segmentation\n",
    "\n",
    "def clip(img, dtype, maxval):\n",
    "    return np.clip(img, 0, maxval).astype(dtype)\n",
    "\n",
    "class DualCompose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        for t in self.transforms:\n",
    "            x, mask = t(x, mask)\n",
    "        return x, mask\n",
    "    \n",
    "class OneOf:\n",
    "    def __init__(self, transforms, prob=0.5):\n",
    "        self.transforms = transforms\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            t = random.choice(self.transforms)\n",
    "            t.prob = 1.\n",
    "            x, mask = t(x, mask)\n",
    "        return x, mask\n",
    "\n",
    "class OneOrOther:\n",
    "    def __init__(self, first, second, prob=0.5):\n",
    "        self.first = first\n",
    "        first.prob = 1.\n",
    "        self.second = second\n",
    "        second.prob = 1.\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            x, mask = self.first(x, mask)\n",
    "        else:\n",
    "            x, mask = self.second(x, mask)\n",
    "        return x, mask\n",
    "\n",
    "\n",
    "class ImageOnly:\n",
    "    def __init__(self, trans):\n",
    "        self.trans = trans\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        return self.trans(x), mask\n",
    "\n",
    "\n",
    "class VerticalFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = cv2.flip(img, 0)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, 0)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class HorizontalFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = cv2.flip(img, 1)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, 1)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            d = random.randint(-1, 1)\n",
    "            img = cv2.flip(img, d)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, d)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class Transpose:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = img.transpose(1, 0, 2)\n",
    "            if mask is not None:\n",
    "                mask = mask.transpose(1, 0, 2)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomRotate90:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            factor = random.randint(0, 4)\n",
    "            img = np.rot90(img, factor)\n",
    "            if mask is not None:\n",
    "                mask = np.rot90(mask, factor)\n",
    "        return img.copy(), mask.copy()\n",
    "\n",
    "\n",
    "class Rotate:\n",
    "    def __init__(self, limit=90, prob=0.5):\n",
    "        self.prob = prob\n",
    "        self.limit = limit\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.limit, self.limit)\n",
    "\n",
    "            height, width = img.shape[0:2]\n",
    "            mat = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, mat, (height, width),\n",
    "                                 flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_REFLECT_101)\n",
    "            if mask is not None:\n",
    "                mask = cv2.warpAffine(mask, mat, (height, width),\n",
    "                                      flags=cv2.INTER_LINEAR,\n",
    "                                      borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    def __init__(self, size):\n",
    "        self.h = size[0]\n",
    "        self.w = size[1]\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        h_start = np.random.randint(0, height - self.h)\n",
    "        w_start = np.random.randint(0, width - self.w)\n",
    "\n",
    "        img = img[h_start: h_start + self.h, w_start: w_start + self.w,:]\n",
    "\n",
    "        assert img.shape[0] == self.h\n",
    "        assert img.shape[1] == self.w\n",
    "\n",
    "        if mask is not None:\n",
    "            if mask.ndim == 2:\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "            mask = mask[h_start: h_start + self.h, w_start: w_start + self.w,:]\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class Shift:\n",
    "    def __init__(self, limit=4, prob=.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            limit = self.limit\n",
    "            dx = round(random.uniform(-limit, limit))\n",
    "            dy = round(random.uniform(-limit, limit))\n",
    "\n",
    "            height, width, channel = img.shape\n",
    "            y1 = limit + 1 + dy\n",
    "            y2 = y1 + height\n",
    "            x1 = limit + 1 + dx\n",
    "            x2 = x1 + width\n",
    "\n",
    "            img1 = cv2.copyMakeBorder(img, limit + 1, limit + 1, limit + 1, limit + 1,\n",
    "                                      borderType=cv2.BORDER_REFLECT_101)\n",
    "            img = img1[y1:y2, x1:x2, :]\n",
    "            if mask is not None:\n",
    "                msk1 = cv2.copyMakeBorder(mask, limit + 1, limit + 1, limit + 1, limit + 1,\n",
    "                                          borderType=cv2.BORDER_REFLECT_101)\n",
    "                mask = msk1[y1:y2, x1:x2, :]\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class ShiftScale:\n",
    "    def __init__(self, limit=4, prob=.25):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        limit = self.limit\n",
    "        if random.random() < self.prob:\n",
    "            height, width, channel = img.shape\n",
    "            assert (width == height)\n",
    "            size0 = width\n",
    "            size1 = width + 2 * limit\n",
    "            size = round(random.uniform(size0, size1))\n",
    "\n",
    "            dx = round(random.uniform(0, size1 - size))\n",
    "            dy = round(random.uniform(0, size1 - size))\n",
    "\n",
    "            y1 = dy\n",
    "            y2 = y1 + size\n",
    "            x1 = dx\n",
    "            x2 = x1 + size\n",
    "\n",
    "            img1 = cv2.copyMakeBorder(img, limit, limit, limit, limit, borderType=cv2.BORDER_REFLECT_101)\n",
    "            img = (img1[y1:y2, x1:x2, :] if size == size0\n",
    "            else cv2.resize(img1[y1:y2, x1:x2, :], (size0, size0), interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "            if mask is not None:\n",
    "                msk1 = cv2.copyMakeBorder(mask, limit, limit, limit, limit, borderType=cv2.BORDER_REFLECT_101)\n",
    "                mask = (msk1[y1:y2, x1:x2, :] if size == size0\n",
    "                else cv2.resize(msk1[y1:y2, x1:x2, :], (size0, size0), interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class ShiftScaleRotate:\n",
    "    def __init__(self, shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, prob=0.5):\n",
    "        self.shift_limit = shift_limit\n",
    "        self.scale_limit = scale_limit\n",
    "        self.rotate_limit = rotate_limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            height, width, channel = img.shape\n",
    "\n",
    "            angle = random.uniform(-self.rotate_limit, self.rotate_limit)\n",
    "            scale = random.uniform(1 - self.scale_limit, 1 + self.scale_limit)\n",
    "            dx = round(random.uniform(-self.shift_limit, self.shift_limit)) * width\n",
    "            dy = round(random.uniform(-self.shift_limit, self.shift_limit)) * height\n",
    "\n",
    "            cc = math.cos(angle / 180 * math.pi) * scale\n",
    "            ss = math.sin(angle / 180 * math.pi) * scale\n",
    "            rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "            box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "            box1 = box0 - np.array([width / 2, height / 2])\n",
    "            box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "            box0 = box0.astype(np.float32)\n",
    "            box1 = box1.astype(np.float32)\n",
    "            mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "            img = cv2.warpPerspective(img, mat, (width, height),\n",
    "                                      flags=cv2.INTER_LINEAR,\n",
    "                                      borderMode=cv2.BORDER_REFLECT_101)\n",
    "            if mask is not None:\n",
    "                mask = cv2.warpPerspective(mask, mat, (width, height),\n",
    "                                           flags=cv2.INTER_NEAREST,\n",
    "                                           borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        self.height = size[0]\n",
    "        self.width = size[1]\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w, c = img.shape\n",
    "        dy = (h - self.height) // 2\n",
    "        dx = (w - self.width) // 2\n",
    "        y1 = dy\n",
    "        y2 = y1 + self.height\n",
    "        x1 = dx\n",
    "        x2 = x1 + self.width\n",
    "        img = img[y1:y2, x1:x2,:]\n",
    "        if mask is not None:\n",
    "            if mask.ndim == 2:\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "            mask = mask[y1:y2, x1:x2,:]\n",
    "\n",
    "        return img, mask\n",
    "    \n",
    "class RandomBrightness:\n",
    "    def __init__(self, limit=0.1, prob=0.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            alpha = 1.0 + self.limit * random.uniform(-1, 1)\n",
    "\n",
    "            maxval = np.max(img[..., :3])\n",
    "            dtype = img.dtype\n",
    "            img[..., :3] = clip(alpha * img[..., :3], dtype, maxval)\n",
    "        return img\n",
    "\n",
    "\n",
    "class RandomContrast:\n",
    "    def __init__(self, limit=.1, prob=.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            alpha = 1.0 + self.limit * random.uniform(-1, 1)\n",
    "\n",
    "            gray = cv2.cvtColor(img[:, :, :3], cv2.COLOR_BGR2GRAY)\n",
    "            gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n",
    "            maxval = np.max(img[..., :3])\n",
    "            dtype = img.dtype\n",
    "            img[:, :, :3] = clip(alpha * img[:, :, :3] + gray, dtype, maxval)\n",
    "        return img\n",
    "\n",
    "\n",
    "train_transform = DualCompose([\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomCrop((256,256,3)),\n",
    "        #ImageOnly(RandomBrightness()),\n",
    "        #ImageOnly(RandomContrast()),\n",
    "])\n",
    "\n",
    "val_transform = DualCompose([\n",
    "        CenterCrop((512,512,3)),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference https://github.com/timctho/unet-pytorch/\n",
    "class UNet_down_block(torch.nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, down_size):\n",
    "        super(UNet_down_block, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.max_pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.down_size = down_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.down_size:\n",
    "            x = self.max_pool(x)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "class UNet_up_block(torch.nn.Module):\n",
    "    def __init__(self, prev_channel, input_channel, output_channel):\n",
    "        super(UNet_up_block, self).__init__()\n",
    "        self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.conv1 = torch.nn.Conv2d(prev_channel + input_channel, output_channel, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, prev_feature_map, x):\n",
    "        x = self.up_sampling(x)\n",
    "        x = torch.cat((x, prev_feature_map), dim=1)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.down_block1 = UNet_down_block(3, 16, False)\n",
    "        self.down_block2 = UNet_down_block(16, 32, True)\n",
    "        self.down_block3 = UNet_down_block(32, 64, True)\n",
    "        self.down_block4 = UNet_down_block(64, 128, True)\n",
    "        self.down_block5 = UNet_down_block(128, 256, True)\n",
    "        self.down_block6 = UNet_down_block(256, 512, True)\n",
    "        self.down_block7 = UNet_down_block(512, 1024, True)\n",
    "\n",
    "        self.mid_conv1 = torch.nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(1024)\n",
    "        self.mid_conv2 = torch.nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(1024)\n",
    "        self.mid_conv3 = torch.nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.up_block1 = UNet_up_block(512, 1024, 512)\n",
    "        self.up_block2 = UNet_up_block(256, 512, 256)\n",
    "        self.up_block3 = UNet_up_block(128, 256, 128)\n",
    "        self.up_block4 = UNet_up_block(64, 128, 64)\n",
    "        self.up_block5 = UNet_up_block(32, 64, 32)\n",
    "        self.up_block6 = UNet_up_block(16, 32, 16)\n",
    "\n",
    "        self.last_conv1 = torch.nn.Conv2d(16, 16, 3, padding=1)\n",
    "        self.last_bn = torch.nn.BatchNorm2d(16)\n",
    "        self.last_conv2 = torch.nn.Conv2d(16, 1, 1, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.down_block1(x)\n",
    "        self.x2 = self.down_block2(self.x1)\n",
    "        self.x3 = self.down_block3(self.x2)\n",
    "        self.x4 = self.down_block4(self.x3)\n",
    "        self.x5 = self.down_block5(self.x4)\n",
    "        self.x6 = self.down_block6(self.x5)\n",
    "        self.x7 = self.down_block7(self.x6)\n",
    "        self.x7 = self.relu(self.bn1(self.mid_conv1(self.x7)))\n",
    "        self.x7 = self.relu(self.bn2(self.mid_conv2(self.x7)))\n",
    "        self.x7 = self.relu(self.bn3(self.mid_conv3(self.x7)))\n",
    "        x = self.up_block1(self.x6, self.x7)\n",
    "        x = self.up_block2(self.x5, x)\n",
    "        x = self.up_block3(self.x4, x)\n",
    "        x = self.up_block4(self.x3, x)\n",
    "        x = self.up_block5(self.x2, x)\n",
    "        x = self.up_block6(self.x1, x)\n",
    "        x = self.relu(self.last_bn(self.last_conv1(x)))\n",
    "        x = self.last_conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model_path ='model_1.pt'\n",
    "state = torch.load(str(model_path))\n",
    "state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
    "model.load_state_dict(state)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Test images\n",
    "\n",
    "For test purposes predict only for 5000 images. Prediction of the full set of images (88500 images) takes more than 6hr !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15606 test images found\n"
     ]
    }
   ],
   "source": [
    "test_paths = os.listdir(test_img_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'ImageId': test_paths, 'EncodedPixels':None})\n",
    "from skimage.morphology import binary_opening, disk\n",
    "test_df=test_df[:5000]\n",
    "loader = DataLoader(\n",
    "        dataset=ShipDataset(test_df, transform=None, mode='predict'),\n",
    "        shuffle=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    ) \n",
    "    \n",
    "out_pred_rows = []\n",
    "for batch_num, (inputs, paths) in enumerate(tqdm(loader, desc='Predict')):\n",
    "    inputs = variable(inputs, volatile=True)\n",
    "    outputs = model(inputs)\n",
    "    for i, image_name in enumerate(paths):\n",
    "        mask = F.sigmoid(outputs[i,0]).data.cpu().numpy()\n",
    "        cur_seg = binary_opening(mask>0.5, disk(2))\n",
    "        cur_rles = multi_rle_encode(cur_seg)\n",
    "        if len(cur_rles)>0:\n",
    "            for c_rle in cur_rles:\n",
    "                out_pred_rows += [{'ImageId': image_name, 'EncodedPixels': c_rle}]\n",
    "        else:\n",
    "            out_pred_rows += [{'ImageId': image_name, 'EncodedPixels': None}]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
